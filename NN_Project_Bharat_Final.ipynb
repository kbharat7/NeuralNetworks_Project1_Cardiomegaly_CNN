{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "009e8fc2",
      "metadata": {
        "id": "009e8fc2"
      },
      "source": [
        "# 1. Build your own convolutional neural network using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os"
      ],
      "metadata": {
        "id": "FUNBxjFUxKn7"
      },
      "id": "FUNBxjFUxKn7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define CNN Model\n",
        "The CustomCNN class defines a convolutional neural network with 7 convolutional layers, followed by pooling and fully connected layers. Dropout is applied before the first fully connected layer to prevent overfitting."
      ],
      "metadata": {
        "id": "5A1aabRH5noT"
      },
      "id": "5A1aabRH5noT"
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNCustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNCustomModel, self).__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(512, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, 512)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LA3zuae7xH1Z"
      },
      "id": "LA3zuae7xH1Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract the dog heart dataset**"
      ],
      "metadata": {
        "id": "uzv2tGxJMxmT"
      },
      "id": "uzv2tGxJMxmT"
    },
    {
      "cell_type": "markdown",
      "id": "a0c45b84",
      "metadata": {
        "id": "a0c45b84"
      },
      "source": [
        "# 2. Train your model using dog heart dataset (you may need to use  Google Colab (or Kaggle) with GPU to train your code)\n",
        "\n",
        "### (1) use torchvision.datasets.ImageFolder for the training dataset\n",
        "### (2) use custom dataloader for test dataset (return image tensor and file name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function\n",
        "The `train_cnn_model` function trains the CNN model using the training and validation datasets, computes the loss and accuracy, and saves the model at the end of training."
      ],
      "metadata": {
        "id": "h3DO_wjB6ZqB"
      },
      "id": "h3DO_wjB6ZqB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the model\n",
        "def train_cnn_model(cnn_model, train_data_loader, val_data_loader, loss_function, optim, epochs=20):\n",
        "    for epoch in range(epochs):\n",
        "        cnn_model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_inputs, batch_labels in train_data_loader:\n",
        "            batch_inputs, batch_labels = batch_inputs.to(device), batch_labels.to(device)\n",
        "            optim.zero_grad()\n",
        "            batch_outputs = cnn_model(batch_inputs)\n",
        "            loss = loss_function(batch_outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total_loss += loss.item() * batch_inputs.size(0)\n",
        "\n",
        "        avg_loss = total_loss / len(train_data_loader.dataset)\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "        # Validate the model\n",
        "        cnn_model.eval()\n",
        "        validation_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_inputs, batch_labels in val_data_loader:\n",
        "                batch_inputs, batch_labels = batch_inputs.to(device), batch_labels.to(device)\n",
        "                batch_outputs = cnn_model(batch_inputs)\n",
        "                loss = loss_function(batch_outputs, batch_labels)\n",
        "                validation_loss += loss.item() * batch_inputs.size(0)\n",
        "                _, predicted_labels = torch.max(batch_outputs, 1)\n",
        "                total_samples += batch_labels.size(0)\n",
        "                correct_predictions += (predicted_labels == batch_labels).sum().item()\n",
        "\n",
        "        avg_val_loss = validation_loss / len(val_data_loader.dataset)\n",
        "        val_accuracy = correct_predictions / total_samples\n",
        "        print(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    # Save the model once at the end\n",
        "    torch.save(cnn_model.state_dict(), 'dog_heart_custom_cnn_v2.pt')\n",
        "    print('Model saved as dog_heart_custom_cnn_v2.pt')"
      ],
      "metadata": {
        "id": "xD-8pXJfeBrZ"
      },
      "id": "xD-8pXJfeBrZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Up Device, Model, and Data Loaders\n",
        "This section checks for GPU availability, sets up the device, instantiates the CNN model, defines transformations, loads the training and validation datasets, and creates data loaders. It also defines the loss function and optimizer."
      ],
      "metadata": {
        "id": "Ph7xRxTm7eOG"
      },
      "id": "Ph7xRxTm7eOG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and use it\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Instantiate the model\n",
        "cnn_model = CNNCustomModel().to(device)\n",
        "print(cnn_model)\n",
        "\n",
        "# Define transformations for the training and validation sets with resizing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((75, 75)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the datasets\n",
        "train_data_directory = '/content/dataset/Dog_heart/Train'  # Path to the training dataset\n",
        "val_data_directory = '/content/dataset/Dog_heart/Valid'  # Path to the validation dataset\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_data_directory, transform=data_transform)\n",
        "val_dataset = datasets.ImageFolder(val_data_directory, transform=data_transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=0.0005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3-h_mqndteA",
        "outputId": "bcf26e54-7b4b-43fa-fe4f-54dc6cddf4f3"
      },
      "id": "G3-h_mqndteA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "CNNCustomModel(\n",
            "  (convs): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): ReLU(inplace=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the Model\n",
        "Call the `train_cnn_model` function to train the CNN model using the specified parameters."
      ],
      "metadata": {
        "id": "y5RMaCzI7x3B"
      },
      "id": "y5RMaCzI7x3B"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_cnn_model(cnn_model, train_data_loader, val_data_loader, loss_function, optimizer, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5wfJrtQemJX",
        "outputId": "559b46e0-1f1c-4f13-8e06-2b5d9538814d"
      },
      "id": "q5wfJrtQemJX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 1.0483\n",
            "Validation Loss: 1.0450, Accuracy: 0.3800\n",
            "Epoch 2/30, Loss: 1.0112\n",
            "Validation Loss: 1.0261, Accuracy: 0.3800\n",
            "Epoch 3/30, Loss: 1.0023\n",
            "Validation Loss: 1.0150, Accuracy: 0.4800\n",
            "Epoch 4/30, Loss: 0.9920\n",
            "Validation Loss: 0.9892, Accuracy: 0.4350\n",
            "Epoch 5/30, Loss: 0.9648\n",
            "Validation Loss: 0.9637, Accuracy: 0.4950\n",
            "Epoch 6/30, Loss: 0.9554\n",
            "Validation Loss: 0.9722, Accuracy: 0.4050\n",
            "Epoch 7/30, Loss: 0.9425\n",
            "Validation Loss: 0.9391, Accuracy: 0.4200\n",
            "Epoch 8/30, Loss: 0.9344\n",
            "Validation Loss: 0.9311, Accuracy: 0.4650\n",
            "Epoch 9/30, Loss: 0.9117\n",
            "Validation Loss: 0.9272, Accuracy: 0.4550\n",
            "Epoch 10/30, Loss: 0.9009\n",
            "Validation Loss: 0.9166, Accuracy: 0.4700\n",
            "Epoch 11/30, Loss: 0.9030\n",
            "Validation Loss: 0.8743, Accuracy: 0.5100\n",
            "Epoch 12/30, Loss: 0.8671\n",
            "Validation Loss: 0.8395, Accuracy: 0.5200\n",
            "Epoch 13/30, Loss: 0.8484\n",
            "Validation Loss: 0.8113, Accuracy: 0.5400\n",
            "Epoch 14/30, Loss: 0.7911\n",
            "Validation Loss: 0.7744, Accuracy: 0.5450\n",
            "Epoch 15/30, Loss: 0.7676\n",
            "Validation Loss: 0.8013, Accuracy: 0.5450\n",
            "Epoch 16/30, Loss: 0.7535\n",
            "Validation Loss: 0.7449, Accuracy: 0.5900\n",
            "Epoch 17/30, Loss: 0.7354\n",
            "Validation Loss: 0.7277, Accuracy: 0.6100\n",
            "Epoch 18/30, Loss: 0.6946\n",
            "Validation Loss: 0.7602, Accuracy: 0.5550\n",
            "Epoch 19/30, Loss: 0.7119\n",
            "Validation Loss: 0.7130, Accuracy: 0.6150\n",
            "Epoch 20/30, Loss: 0.6777\n",
            "Validation Loss: 0.7175, Accuracy: 0.6050\n",
            "Epoch 21/30, Loss: 0.6705\n",
            "Validation Loss: 0.7138, Accuracy: 0.6150\n",
            "Epoch 22/30, Loss: 0.6622\n",
            "Validation Loss: 0.6962, Accuracy: 0.6150\n",
            "Epoch 23/30, Loss: 0.6427\n",
            "Validation Loss: 0.6937, Accuracy: 0.6350\n",
            "Epoch 24/30, Loss: 0.6137\n",
            "Validation Loss: 0.7020, Accuracy: 0.6100\n",
            "Epoch 25/30, Loss: 0.6239\n",
            "Validation Loss: 0.6801, Accuracy: 0.6600\n",
            "Epoch 26/30, Loss: 0.6125\n",
            "Validation Loss: 0.6674, Accuracy: 0.6500\n",
            "Epoch 27/30, Loss: 0.5842\n",
            "Validation Loss: 0.7074, Accuracy: 0.6700\n",
            "Epoch 28/30, Loss: 0.5676\n",
            "Validation Loss: 0.6913, Accuracy: 0.6550\n",
            "Epoch 29/30, Loss: 0.5523\n",
            "Validation Loss: 0.7226, Accuracy: 0.6500\n",
            "Epoch 30/30, Loss: 0.5505\n",
            "Validation Loss: 0.6829, Accuracy: 0.6650\n",
            "Model saved as dog_heart_custom_cnn_v2.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Custom Test Dataset\n",
        "This section defines a custom dataset class, `TestDataset`, to load test images from a specified directory. The class includes methods to get the length of the dataset and to retrieve an image and its path given an index."
      ],
      "metadata": {
        "id": "MqN2uvWi81jT"
      },
      "id": "MqN2uvWi81jT"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import csv\n",
        "\n",
        "class CustomTestDataset(Dataset):\n",
        "    def __init__(self, directory, transform=None):\n",
        "        self.directory = directory\n",
        "        self.transform = transform\n",
        "        self.image_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(('jpg', 'jpeg', 'png'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_files[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, image_path"
      ],
      "metadata": {
        "id": "VQlm1JCtrGBQ"
      },
      "id": "VQlm1JCtrGBQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Test Data\n",
        "Define transformations, create an instance of the custom test dataset, and create a DataLoader for the test set without shuffling to maintain order."
      ],
      "metadata": {
        "id": "5iXCL4Pc89f_"
      },
      "id": "5iXCL4Pc89f_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "test_data_transform = transforms.Compose([\n",
        "    transforms.Resize((75, 75)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create an instance of the dataset\n",
        "test_data_directory = '/content/dataset/Test'  # Path to the test dataset\n",
        "custom_test_dataset = CustomTestDataset(test_data_directory, transform=test_data_transform)\n",
        "\n",
        "# Create DataLoader for the test set\n",
        "test_data_loader = DataLoader(custom_test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "IyrrUCrXrkwj"
      },
      "id": "IyrrUCrXrkwj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Predictions\n",
        "Define a function, `generate_predictions`, to evaluate the model on the test set and generate predictions. The function returns a list of image filenames and their predicted labels."
      ],
      "metadata": {
        "id": "fY7d4dKT9X7b"
      },
      "id": "fY7d4dKT9X7b"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_model_predictions(cnn_model, test_data_loader):\n",
        "    cnn_model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch_inputs, image_paths in test_data_loader:\n",
        "            batch_inputs = batch_inputs.to(device)\n",
        "            batch_outputs = cnn_model(batch_inputs)\n",
        "            _, predicted_labels = torch.max(batch_outputs, 1)\n",
        "            for idx in range(len(image_paths)):\n",
        "                predictions.append([os.path.basename(image_paths[idx]), predicted_labels[idx].item()])\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "wvOFwr7lsBuJ"
      },
      "id": "wvOFwr7lsBuJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and Save Predictions\n",
        "Load the trained model, generate predictions on the test set, and save the results to a CSV file.\n"
      ],
      "metadata": {
        "id": "t9Io0guS9e9W"
      },
      "id": "t9Io0guS9e9W"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "cnn_model.load_state_dict(torch.load('dog_heart_custom_cnn_v2.pt'))\n",
        "cnn_model.to(device)\n",
        "\n",
        "# Generate predictions\n",
        "predicted_results = generate_model_predictions(cnn_model, test_data_loader)\n",
        "\n",
        "# Save to CSV\n",
        "output_csv_file = 'test_results_bharat.csv'\n",
        "with open(output_csv_file, mode='w', newline='') as file:\n",
        "    csv_writer = csv.writer(file)\n",
        "    csv_writer.writerows(predicted_results)\n",
        "\n",
        "print(f'Results saved to {output_csv_file}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgAuMKjhsFYl",
        "outputId": "57fc9a58-cda5-4452-f6b4-7bae8faa5014"
      },
      "id": "sgAuMKjhsFYl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to test_results_bharat.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reload and Verify CSV\n",
        "Reload the generated CSV file and verify its contents by checking the number of rows and displaying the first few entries.\n"
      ],
      "metadata": {
        "id": "zC7Y4RhG9lEC"
      },
      "id": "zC7Y4RhG9lEC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the CSV and verify\n",
        "import pandas as pd\n",
        "loaded_results = pd.read_csv('test_results_bharat.csv', header=None)\n",
        "num_rows = len(loaded_results)\n",
        "sample_entries = loaded_results.head()\n",
        "\n",
        "num_rows, sample_entries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fymR0VGUvHWv",
        "outputId": "99113333-305c-44d0-bcce-ac2e385f02fb"
      },
      "id": "fymR0VGUvHWv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400,\n",
              "           0  1\n",
              " 0  1678.png  1\n",
              " 1  1715.png  2\n",
              " 2  1910.png  1\n",
              " 3  1670.png  0\n",
              " 4  1724.png  2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f63262f",
      "metadata": {
        "id": "7f63262f"
      },
      "source": [
        "# 3. Evaluate your model using the developed software"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "m-ZbSoNxbpZ-"
      },
      "id": "m-ZbSoNxbpZ-"
    },
    {
      "cell_type": "markdown",
      "id": "1b5846bc",
      "metadata": {
        "id": "1b5846bc"
      },
      "source": [
        "# 4. Compare results with [RVT paper](https://www.nature.com/articles/s41598-023-50063-x). Requirement: performance is better than VGG16: 70%"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison of Custom CNN Model Results with VGG-16 from Literature\n",
        "The custom CNN model achieved a test accuracy of **66.75%** on the dog heart dataset. This result is highly encouraging, especially considering that the VGG-16 model referenced in the paper [\"Nature - s41598-023-50063-x\"](https://www.nature.com/articles/s41598-023-50063-x) reported a validation performance of approximately **70%**.\n",
        "\n",
        "While the VGG-16 model is a well-established, pre-trained model known for its depth and complexity, the custom CNN model was built from scratch with seven convolutional layers and achieved performance close to VGG-16's results. This demonstrates the robustness and effectiveness of the custom architecture in identifying complex patterns within the dataset.\n",
        "\n",
        "Given that the custom CNN model is specifically tailored to the dataset, further fine-tuning and optimization could potentially lead to even higher accuracy. The current performance highlights the model's strong foundation and the promising potential for future improvements. This result underscores the value of custom models, particularly when computational resources or specific dataset characteristics necessitate a more tailored approach than pre-trained models can provide."
      ],
      "metadata": {
        "id": "a65ei1uhFoX8"
      },
      "id": "a65ei1uhFoX8"
    },
    {
      "cell_type": "markdown",
      "id": "62f12835",
      "metadata": {
        "id": "62f12835"
      },
      "source": [
        "# 5. Write a four-page paper report using the shared LaTex template. Upload your paper to ResearchGate or Arxiv, and put your paper link and GitHub weight link here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### https://www.researchgate.net/publication/382110674_Automatic_Classification_of_Dog_Cardiomegaly_Using_a_Convolutional_Neural_Network"
      ],
      "metadata": {
        "id": "5qHWmXAuhjcX"
      },
      "id": "5qHWmXAuhjcX"
    },
    {
      "cell_type": "markdown",
      "id": "f476372c",
      "metadata": {
        "id": "f476372c"
      },
      "source": [
        "# 6. Grading rubric\n",
        "\n",
        "(1). Code ------- 20 points (you also need to upload your final model as a pt file)\n",
        "\n",
        "(2). Grammer ---- 20 points\n",
        "\n",
        "(3). Introduction & related work --- 10 points\n",
        "\n",
        "\n",
        "(4). Method  ---- 20 points\n",
        "\n",
        "(5). Results ---- 20 points\n",
        "\n",
        "     > = 70 % -->10 points\n",
        "     < 50 % -->0 points\n",
        "     >= 50 % & < 70% --> 0.5 point/percent\n",
        "     \n",
        "\n",
        "(6). Discussion - 10 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445593c4",
      "metadata": {
        "id": "445593c4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}